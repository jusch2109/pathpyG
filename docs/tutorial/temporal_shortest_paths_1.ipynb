{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pathpyG as pp\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "from pathpyG import Graph, TemporalGraph, MultiOrderModel\n",
    "\n",
    "pp.config['torch']['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> 0\n",
      "b -> 1\n",
      "c -> 2\n",
      "d -> 3\n",
      "e -> 4\n",
      "\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n",
    "              ('c', 'd', 5), ('b', 'e', 5), ('c', 'b', 6)]\n",
    "t = pp.TemporalGraph.from_edge_list(tedges)\n",
    "print(t.mapping)\n",
    "print(t.N)\n",
    "print(t.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_respecting_paths(g: TemporalGraph, delta: float) -> defaultdict:\n",
    "    \"\"\"\n",
    "    Calculate all longest time-respecting paths in a temporal graph.\n",
    "    \"\"\"\n",
    "    paths_of_length = {}\n",
    "    in_degree = degree(g.data.edge_index[1], num_nodes=g.N)\n",
    "\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n",
    "    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n",
    "\n",
    "    # second-order edge index\n",
    "    null_model_edge_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n",
    "    # Update node sequences\n",
    "    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n",
    "    # Remove non-time-respecting higher-order edges\n",
    "    time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n",
    "    non_negative_mask = time_diff > 0\n",
    "    delta_mask = time_diff <= delta\n",
    "    time_respecting_mask = non_negative_mask & delta_mask\n",
    "    edge_index = null_model_edge_index[:, time_respecting_mask]\n",
    "    \n",
    "    # calculate degrees\n",
    "    out_degree = degree(edge_index[0], num_nodes=g.M, dtype=torch.long)\n",
    "    in_degree = degree(edge_index[1], num_nodes=g.M, dtype=torch.long)\n",
    "    # identify root nodes with in-degree zero\n",
    "    roots = torch.where(in_degree == 0)[0]\n",
    "    leafs = (out_degree == 0)\n",
    "    paths = node_sequence[roots]\n",
    "    #paths_of_length[1] = paths[leafs[roots]].tolist()\n",
    "\n",
    "    paths = paths[~leafs[roots]]\n",
    "    nodes = roots[~leafs[roots]]\n",
    "\n",
    "    ptrs = cumsum(out_degree, dim=0)\n",
    "\n",
    "    # create traversable graph\n",
    "    event_dag = Graph.from_edge_index(edge_index)\n",
    "\n",
    "    # count all longest time-respecting paths in the temporal graph\n",
    "    step = 1\n",
    "    while nodes.size(0) > 0:\n",
    "        print(\"step\", step)\n",
    "        idx_repeat = torch.repeat_interleave(out_degree[nodes])\n",
    "        next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])\n",
    "        idx_correction = torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]\n",
    "        next_idx += idx_correction\n",
    "        next_nodes = edge_index[1][next_idx]\n",
    "        paths = torch.cat([paths[idx_repeat], node_sequence[next_nodes, 1:]], dim=1)\n",
    "        # paths_of_length[step] = paths[leafs[next_nodes]].tolist()\n",
    "        paths = paths[~leafs[next_nodes]]\n",
    "        nodes = next_nodes[~leafs[next_nodes]]\n",
    "        # print(edge_index)\n",
    "        # print([g.mapping.to_id(v[0].item()) for v in node_sequence[nodes]])\n",
    "        # print(next_idx)\n",
    "        # print([g.mapping.to_id(v[1].item()) for v in node_sequence[next_nodes]])\n",
    "        # print(paths)\n",
    "        step += 1\n",
    "    return None #paths_of_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Graph with 89 nodes, 947 unique edges and 1911 events in [0.0, 1438.0]\n",
      "\n",
      "Graph attributes\n",
      "\tsrc\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\tdst\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\tt\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = pp.TemporalGraph.from_csv('ants_1_1.tedges')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 5\n",
      "step 6\n",
      "step 7\n",
      "step 8\n",
      "step 9\n",
      "step 10\n",
      "step 11\n",
      "step 12\n",
      "step 13\n",
      "step 14\n",
      "step 15\n",
      "step 16\n",
      "step 17\n",
      "step 18\n",
      "step 19\n",
      "step 20\n",
      "step 21\n",
      "step 22\n",
      "step 23\n",
      "step 24\n",
      "step 25\n",
      "step 26\n",
      "step 27\n",
      "step 28\n",
      "step 29\n",
      "step 30\n",
      "step 31\n",
      "step 32\n",
      "step 33\n",
      "step 34\n",
      "step 35\n",
      "step 36\n",
      "step 37\n",
      "step 38\n",
      "step 39\n",
      "step 40\n",
      "step 41\n",
      "step 42\n",
      "step 43\n",
      "step 44\n",
      "step 45\n",
      "step 46\n",
      "step 47\n",
      "step 48\n",
      "step 49\n",
      "step 50\n",
      "step 51\n",
      "step 52\n",
      "step 53\n",
      "step 54\n",
      "step 55\n",
      "step 56\n"
     ]
    }
   ],
   "source": [
    "paths = time_respecting_paths(t, delta=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383646"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths of length 2:\n",
      "['d', 'c', 'b']\n",
      "['d', 'c', 'd']\n",
      "Paths of length 3:\n",
      "['a', 'b', 'c', 'd']\n",
      "['a', 'b', 'c', 'd']\n",
      "Paths of length 4:\n",
      "['a', 'b', 'a', 'b', 'e']\n",
      "['a', 'b', 'c', 'b', 'e']\n",
      "['a', 'b', 'a', 'b', 'e']\n",
      "['a', 'b', 'c', 'b', 'e']\n"
     ]
    }
   ],
   "source": [
    "for k, v in paths.items():\n",
    "    print(f\"Paths of length {k+1}:\")\n",
    "    for p in v:\n",
    "        print([t.mapping.to_id(v) for v in p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 10 nodes and 14 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function pathpyG.algorithms.centrality.temporal_closeness_centrality.<locals>.<lambda>()>,\n",
       "            {'b': 0.8333333333333333,\n",
       "             'd': 0.3333333333333333,\n",
       "             'e': 0.5,\n",
       "             'a': 0.0,\n",
       "             'c': 0.0})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.centrality.temporal_closeness_centrality(t, delta=5, normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 17 nodes and 7 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/13\n",
      "Processing root 11/13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function pathpyG.algorithms.centrality.temporal_betweenness_centrality.<locals>.<lambda>()>,\n",
       "            {'b': 2.0,\n",
       "             'c': 2.5,\n",
       "             'g': 0.5,\n",
       "             'f': 1.0,\n",
       "             'a': 1.0,\n",
       "             'd': 0,\n",
       "             'e': 0,\n",
       "             'h': 0,\n",
       "             'i': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.centrality.temporal_betweenness_centrality(t, delta=5, normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 17 nodes and 7 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/13\n",
      "Processing root 11/13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>()>,\n",
       "             {'a': defaultdict(set,\n",
       "                          {'b': {('a', 'b')},\n",
       "                           'd': {('a', 'b', 'c', 'd')},\n",
       "                           'e': {('a', 'b', 'c', 'e')},\n",
       "                           'h': {('a', 'c', 'h'), ('a', 'g', 'h')}}),\n",
       "              'b': defaultdict(set, {'f': {('b', 'f')}, 'i': {('b', 'i')}}),\n",
       "              'c': defaultdict(set,\n",
       "                          {'f': {('c', 'f')},\n",
       "                           'i': {('c', 'i')},\n",
       "                           'g': {('c', 'f', 'a', 'g')}}),\n",
       "              'f': defaultdict(set, {'h': {('f', 'h')}}),\n",
       "              'h': defaultdict(set, {'f': {('h', 'f')}, 'i': {('h', 'i')}}),\n",
       "              'i': defaultdict(set, {'b': {('i', 'b')}})}),\n",
       " defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>()>,\n",
       "             {'a': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'b': 1, 'd': 3, 'e': 3, 'h': 2}),\n",
       "              'b': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'f': 1, 'i': 1}),\n",
       "              'c': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'f': 1, 'i': 1, 'g': 3}),\n",
       "              'f': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'h': 1}),\n",
       "              'h': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'f': 1, 'i': 1}),\n",
       "              'i': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'b': 1})}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.temporal_shortest_paths(t, delta=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> 0\n",
      "b -> 1\n",
      "c -> 2\n",
      "d -> 3\n",
      "\n",
      "4\n",
      "7\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 17 nodes and 3 edges\n",
      "\n",
      "Node attributes\n",
      "\tnode_sequence\t\t<class 'torch.Tensor'> -> torch.Size([17, 2])\n",
      "\n",
      "Edge attributes\n",
      "\tedge_weight\t\t<class 'torch.Tensor'> -> torch.Size([3])\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "(('a', 'c'), ('c', 'h')) tensor(1.)\n",
      "(('a', 'g'), ('g', 'h')) tensor(1.)\n",
      "(('c', 'f'), ('f', 'a')) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "m = pp.MultiOrderModel.from_temporal_graph(t, max_order=4, delta=2)\n",
    "print(m.layers[2])\n",
    "for i, e in enumerate(m.layers[2].edges):\n",
    "    print(e, m.layers[2].data.edge_weight[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1 -> slow\n",
    "def temporal_shortest_paths(g: pp.TemporalGraph, delta, max_k) -> defaultdict:\n",
    "    \"\"\"\n",
    "    Calculates all shortest paths between all pairs of nodes \n",
    "    based on a set of empirically observed paths.\n",
    "    \"\"\"\n",
    "    sp = defaultdict(lambda: defaultdict(set))\n",
    "    sp_lengths = torch.full((g.N, g.N), float('inf'))\n",
    "    sp_lengths.fill_diagonal_(float(0))\n",
    "    out_degree=degree(g.data.edge_index[0],num_nodes=g.N)\n",
    "    in_degree =degree(g.data.edge_index[1],num_nodes=g.N)\n",
    "\n",
    "    sp_lengths[out_degree==0]=0\n",
    "    sp_lengths[:,in_degree==0]=0\n",
    "    print(sp_lengths)\n",
    "\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n",
    "    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n",
    "    k = 1\n",
    "    while torch.max(sp_lengths) > k and edge_index.size(1)>0 and k < max_k:\n",
    "\n",
    "        print(f'k = {k}, edge_index size = {edge_index.size(1)}')\n",
    "        #print(f'node_sequences = {node_sequences}')\n",
    "        # check for shorter paths with length k\n",
    "        src, tgt = edge_index\n",
    "        for i in range(edge_index.size(1)):\n",
    "            u = node_sequence[src[i]][0]\n",
    "            v = node_sequence[tgt[i]][-1]\n",
    "            if k < sp_lengths[u][v]:\n",
    "                path = torch.cat([node_sequence[src[i]], v.unsqueeze(dim=0)])\n",
    "                sp_lengths[u][v] = k\n",
    "                sp[u][v] = set([g.mapping.to_id(x.item()) for x in path])\n",
    "            elif k == sp_lengths[u][v]:\n",
    "                path = torch.cat([node_sequence[src[i]], v.unsqueeze(dim=0)])\n",
    "                sp[u][v].add(tuple([g.mapping.to_id(x.item()) for x in path]))\n",
    "                 \n",
    "\n",
    "        if k==1:\n",
    "            null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n",
    "            # Update node sequences\n",
    "            node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n",
    "            # Remove non-time-respecting higher-order edges\n",
    "            time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n",
    "            non_negative_mask = time_diff > 0\n",
    "            delta_mask = time_diff <= delta\n",
    "            time_respecting_mask = non_negative_mask & delta_mask\n",
    "            edge_index = null_model_edge_index[:, time_respecting_mask]\n",
    "        else:\n",
    "            edge_index, node_sequence, _, _ = pp.MultiOrderModel.iterate_lift_order(edge_index, node_sequence, mapping=g.mapping)\n",
    "        k += 1\n",
    "    return sp_lengths, sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "def routes_from_node(g, v, node_sequence, mapping):\n",
    "    \"\"\"\n",
    "    Constructs all paths from node v to any leaf node\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v:\n",
    "        node from which to start\n",
    "    node_mapping: dict\n",
    "        an optional mapping from node to a different set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Counter\n",
    "    \"\"\"\n",
    "    # Collect temporary paths, indexed by the target node\n",
    "    temp_paths = defaultdict(list)\n",
    "    temp_paths[v] = [[mapping.to_id(node_sequence[v][0].item())]]\n",
    "\n",
    "    # set of unprocessed nodes\n",
    "    queue = {v}\n",
    "\n",
    "    while queue:\n",
    "        # take one unprocessed node\n",
    "        x = queue.pop()\n",
    "\n",
    "        # successors of x expand all temporary\n",
    "        # paths, currently ending in x\n",
    "        s = g.get_successors(x)\n",
    "        for w in s:\n",
    "            w = w.item()\n",
    "            for p in temp_paths[x]:\n",
    "                temp_paths[w].append(p + [mapping.to_id(node_sequence[w][1].item())])\n",
    "            queue.add(w)\n",
    "        if s.size(0) > 0:\n",
    "            del temp_paths[x]\n",
    "    # flatten dictionary\n",
    "    return temp_paths    \n",
    "\n",
    "def temporal_shortest_paths(g: pp.TemporalGraph, delta) -> defaultdict:\n",
    "    \"\"\"\n",
    "    Calculates all shortest paths between all pairs of nodes \n",
    "    based on a set of empirically observed paths.\n",
    "    \"\"\"\n",
    "    sp = defaultdict(lambda: defaultdict(set))\n",
    "    sp_lengths = torch.full((g.N, g.N), float('inf'))\n",
    "    sp_lengths.fill_diagonal_(float(0))\n",
    "    out_degree=degree(g.data.edge_index[0],num_nodes=g.N)\n",
    "    in_degree =degree(g.data.edge_index[1],num_nodes=g.N)\n",
    "\n",
    "    sp_lengths[out_degree==0]=0\n",
    "    sp_lengths[:,in_degree==0]=0\n",
    "    print(sp_lengths)\n",
    "\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n",
    "    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n",
    "    k = 1\n",
    "\n",
    "    # second-order edge index\n",
    "    null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n",
    "    # Update node sequences\n",
    "    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n",
    "    # Remove non-time-respecting higher-order edges\n",
    "    time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n",
    "    non_negative_mask = time_diff > 0\n",
    "    delta_mask = time_diff <= delta\n",
    "    time_respecting_mask = non_negative_mask & delta_mask\n",
    "    edge_index = null_model_edge_index[:, time_respecting_mask]\n",
    "    \n",
    "    # identify root nodes with in-degree zero\n",
    "    in_degree = degree(edge_index[1],num_nodes=g.M)\n",
    "    roots = torch.where(in_degree==0)[0]\n",
    "\n",
    "    # create traversable graph\n",
    "    event_dag = pp.Graph.from_edge_index(edge_index)\n",
    "    print(event_dag)\n",
    "\n",
    "    # count all longest time-respecting paths in the temporal graph\n",
    "    paths = []\n",
    "    i = 0\n",
    "    for r in roots:\n",
    "        print(f'processing root {i+1}/{roots.size(0)}')\n",
    "        root_paths = routes_from_node(event_dag, r.item(), node_sequence, g.mapping)\n",
    "        print(f'\\t found {len(root_paths)} paths')\n",
    "        for x in root_paths:\n",
    "            for p in root_paths[x]:\n",
    "                paths.append(p)\n",
    "        i += 1\n",
    "    print(len(paths))\n",
    "    return sp_lengths, sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_lengths, sp = temporal_shortest_paths(t, delta=100)\n",
    "print(sp_lengths)\n",
    "print(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Graph with 89 nodes, 947 unique edges and 1911 events in [0.0, 1438.0]\n",
      "\n",
      "Graph attributes\n",
      "\tt\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\tsrc\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\tdst\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t = pp.TemporalGraph.from_csv('ants_1_1.tedges')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = temporal_shortest_paths(t, delta=30)\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 1910 nodes and 2518 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/597\n",
      "Processing root 11/597\n",
      "Processing root 21/597\n",
      "Processing root 31/597\n",
      "Processing root 41/597\n",
      "Processing root 51/597\n",
      "Processing root 61/597\n",
      "Processing root 71/597\n",
      "Processing root 81/597\n",
      "Processing root 91/597\n",
      "Processing root 101/597\n",
      "Processing root 111/597\n",
      "Processing root 121/597\n",
      "Processing root 131/597\n",
      "Processing root 141/597\n",
      "Processing root 151/597\n",
      "Processing root 161/597\n",
      "Processing root 171/597\n",
      "Processing root 181/597\n",
      "Processing root 191/597\n",
      "Processing root 201/597\n",
      "Processing root 211/597\n",
      "Processing root 221/597\n",
      "Processing root 231/597\n",
      "Processing root 241/597\n",
      "Processing root 251/597\n",
      "Processing root 261/597\n",
      "Processing root 271/597\n",
      "Processing root 281/597\n",
      "Processing root 291/597\n",
      "Processing root 301/597\n",
      "Processing root 311/597\n",
      "Processing root 321/597\n",
      "Processing root 331/597\n",
      "Processing root 341/597\n",
      "Processing root 351/597\n",
      "Processing root 361/597\n",
      "Processing root 371/597\n",
      "Processing root 381/597\n",
      "Processing root 391/597\n",
      "Processing root 401/597\n",
      "Processing root 411/597\n",
      "Processing root 421/597\n",
      "Processing root 431/597\n",
      "Processing root 441/597\n",
      "Processing root 451/597\n",
      "Processing root 461/597\n",
      "Processing root 471/597\n",
      "Processing root 481/597\n",
      "Processing root 491/597\n",
      "Processing root 501/597\n",
      "Processing root 511/597\n",
      "Processing root 521/597\n",
      "Processing root 531/597\n",
      "Processing root 541/597\n",
      "Processing root 551/597\n",
      "Processing root 561/597\n",
      "Processing root 571/597\n",
      "Processing root 581/597\n",
      "Processing root 591/597\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "paths = pp.algorithms.time_respecting_paths(t, delta=30)\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sp_lengths[sp_lengths < 100].flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0,1,2])\n",
    "b = torch.tensor([1,2,3])\n",
    "torch.cat([a, b[-1].unsqueeze(dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in torch.tensor([0,1]):\n",
    "    print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
