{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathpyG as pp\n",
    "pp.config['torch']['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PahtpyG takes as input various types of data: \n",
    "- Paths: DAG class\n",
    "- DAGs: DAG class \n",
    "- Edgelists: DAG e network\n",
    "- Time stamped interactions (events)\n",
    "\n",
    "\n",
    "These data can then be represented with different types of models: \n",
    "- Network: Graph class\n",
    "- Higher-Order Network (as layers of a mon)\n",
    "- Multi-Order network\n",
    "- Temporal Network\n",
    "\n",
    "The focus of the package is teh ability to represent, model, use, memory in interactions within statistical, machine learning, and deep learning methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passing walks to DAG class**\n",
    "\n",
    "Walks can be passed in different ways. \n",
    "The most intuitive ways is to pass them as tuples (iterables?)  to a DAGData object.\n",
    "This approach requires a mapping from string ids to node indices (these mappings are handled by IndexMap). \n",
    "Such a mapping can be conveniently obtained intitializing a network object.\n",
    "The network object represent the topological backbone traversed by the walk dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGData with 2 dags with total weight 3.0\n"
     ]
    }
   ],
   "source": [
    "g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c')])\n",
    "dags = pp.DAGData(mapping = g.mapping)\n",
    "\n",
    "dags.append_walk(('a', 'b', 'c', 'b'), weight=1.0)\n",
    "dags.append_walk(('a', 'c'), weight = 2.0)\n",
    "print(dags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "otehrwise, we can independently initilize an EdgeIndex object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGData with 2 dags with total weight 3.0\n"
     ]
    }
   ],
   "source": [
    "dags = pp.DAGData(pp.IndexMap(list(\"abc\")))\n",
    "dags.append_walk(('a', 'b', 'c', 'b'), weight=1.0)\n",
    "dags.append_walk(('a', 'c'), weight = 2.0)\n",
    "print(dags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can pass walks as edge indices without specifying a mapping. \n",
    "Notice that for the node indices to represent a valid walk, all subsequent edges must be adjecent.\n",
    "In the edge_index format, this means that i-th element of the target indices must be equal to i+1 element of the source indices. \n",
    "Intuitively, this represents the fact that the node receives the path as a target and then propagates the path as a source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGData with 2 dags with total weight 3\n"
     ]
    }
   ],
   "source": [
    "dags = pp.DAGData()\n",
    "dags.append_dag(torch.tensor([[1,2,3,4],[2,3,4,5]]), weight=1)\n",
    "dags.append_dag(torch.tensor([[3,4,5,6],[4,5,6,7]]), weight=2)\n",
    "print(dags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passing DAGs to DAG class**\n",
    "\n",
    "Naturally, we can also pass DAGs to the DAG class. \n",
    "Both with and without IndexMap, the operation is now perfomed using the append_dag method. \n",
    "In a dag, we are no longer constrained to pass edge indices where the i-th element for the target is equal to the i+1 elemen fof the source.  \n",
    "This is a consequence of the fact that DAGs have bifurcations while walks, by definition, cannot. \n",
    "The edge_index of a DAG represents source target intearctions in the dag. \n",
    "[[0,0][1,2]] represents the root node (at t_0) interacting with three other nodes at times t_1, t_2. \n",
    "\n",
    "\n",
    "Notice that the current implementation of the DAG class cannot represent DAGs with the same node appearing at different times. \n",
    "For example, in [[0,0,1],[1,2,2]] we are saying that the node with index 1 hits the same 2 that was hit by 0 (i.e., 2 as indegree 2). \n",
    "This representation, however, does not allow us to say that 2 hits 1 at a later time (leading to two copies of the node, both with indegree one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dags = pp.DAGData()\n",
    "dags.append_dag(torch.tensor([[0,0,1],[1,2,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(edge_index=[2, 3], node_sequence=[3, 1], num_nodes=3, edge_weight=[3])]\n"
     ]
    }
   ],
   "source": [
    "dags = pp.DAGData(pp.IndexMap(list(\"abc\")))\n",
    "dags.append_dag(torch.tensor([[0,0,1],[1,2,2]]))\n",
    "print(dags.dags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passing Walks and DAGs**\n",
    "Finally, we can pass both walks and dags at the same time\n",
    "\n",
    "CURRELTY BUGGY (bug appears when training a multi order network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGData with 2 dags with total weight 3.0\n"
     ]
    }
   ],
   "source": [
    "# Example with mix of walks or dags\n",
    "dags = pp.DAGData(mapping = g.mapping)\n",
    "\n",
    "dags.append_dag(torch.tensor([[0,0,1],[1,2,2]]), weight=2)\n",
    "dags.append_walk(('a', 'b', 'c'))\n",
    "print(dags)\n",
    "\n",
    "m = pp.MultiOrderModel.from_DAGs(dags, max_order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(torch.tensor([2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric\n",
    "# import torch_geometric.utils\n",
    "we = torch_geometric.utils.cumsum(torch.tensor([1,1,1,1,1,1]), dim = 0)[:-1]\n",
    "torch.repeat_interleave(we)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Order model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_outdegrees(graph):\n",
    "    weighted_outdegree = scatter(graph.data.edge_weight, graph.data.edge_index[0], dim=0, dim_size=graph.data.num_nodes, reduce='sum')\n",
    "    return weighted_outdegree\n",
    "\n",
    "def compute_transition_probabilities(graph):\n",
    "    weighted_outdegree = compute_weighted_outdegrees(graph)\n",
    "    source_ids = graph.data.edge_index[0]\n",
    "    return graph.data.edge_weight/ weighted_outdegree[source_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 62, 140,  61, 141,  61, 141])\n",
      "tensor([ 61,   1, 140,  61, 141,  31,  70])\n",
      "tensor([1.0000, 1.0000, 0.3020, 0.6980, 1.0000, 1.0000])\n",
      "tensor([0.9839, 0.0161, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "dag_data = pp.DAGData(pp.IndexMap(list(\"01234\")))\n",
    "\n",
    "# dag_data.append_dag(torch.tensor([[0,2],[2,3]]), weight=20)\n",
    "# dag_data.append_dag(torch.tensor([[1,2],[2,4]]), weight=20)\n",
    "# print(dag_data)\n",
    "\n",
    "dag_data.append_walk(list(\"0230230\"), weight=30)\n",
    "dag_data.append_walk(list(\"1241241\"), weight=70)\n",
    "dag_data.append_walk(list(\"0230241\"), weight=1)\n",
    "\n",
    "m = pp.MultiOrderModel.from_DAGs(dag_data, max_order=7)\n",
    "\n",
    "hon_1 = m.layers[1]\n",
    "hon_2 = m.layers[2]\n",
    "hon_3 = m.layers[3]\n",
    "hon_4 = m.layers[4]\n",
    "hon_5 = m.layers[5]\n",
    "hon_6 = m.layers[5]\n",
    "hon_7 = m.layers[7]\n",
    "print(hon_1.data.edge_weight)\n",
    "print(hon_2.data.edge_weight)\n",
    "\n",
    "t_1 = compute_transition_probabilities(hon_1)\n",
    "t_2 = compute_transition_probabilities(hon_2)\n",
    "\n",
    "print(t_1)\n",
    "print(t_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_general_bipartite_edge_index(g_source, g_target) -> torch.Tensor:\n",
    "    \"\"\"Generate edge_index for bipartite graph connecting nodes of higher-order graphs with arbitrary (but different) orders.\"\"\"\n",
    "    order_source = g_source.data.node_sequence[0].shape[0]\n",
    "    order_target = g_target.data.node_sequence[0].shape[0]\n",
    "    assert order_source!= order_target, \"Source and target must have different orders to generate bipartite indices\"\n",
    "    node_sequence_source = g_source.data.node_sequence\n",
    "    node_sequence_target = g_target.data.node_sequence\n",
    "    d_order = max(order_source, order_target) - min(order_source, order_target)\n",
    "    if order_source>order_target:\n",
    "        mask = torch.all(node_sequence_target[:,None] == node_sequence_source[:, d_order:], dim=-1).T\n",
    "        bip_tensor = torch.nonzero(mask, as_tuple=False).T\n",
    "    else:\n",
    "        mask = torch.all(node_sequence_source[:, None] == node_sequence_target[:, :-d_order], dim=-1)\n",
    "        bip_tensor = torch.nonzero(mask, as_tuple=False).T\n",
    "    return bip_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# class Lh_conv(torch_geometric.nn.MessagePassing):\n",
    "#     def __init__(self):\n",
    "#         super().__init__(aggr=\"sum\", flow=\"source_to_target\", node_dim = -1)\n",
    "#     def forward(self, x_source, source_to_target_edge_index, transition_probability):\n",
    "        \n",
    "#         N = len(source_to_target_edge_index[0].unique())\n",
    "#         M = len(source_to_target_edge_index[1].unique())\n",
    "\n",
    "#         return self.propagate(\n",
    "#                     source_to_target_edge_index,\n",
    "#                     size = (N,M),\n",
    "#                     x = (x_source, None),\n",
    "#                     transition_probability = transition_probability\n",
    "#                     )\n",
    "\n",
    "#     def message(self, x_j, transition_probability):\n",
    "#         return x_j + np.log(transition_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lh_conv = Lh_conv()\n",
    "# x_source = torch.tensor([np.log(1)]) # lh of path until now # here 1 cause considering the example of a path set{(0,0),(0,1)}, hence only have a deterministic 0th transition *->0\n",
    "# # x_target = None # these are gonna be genetaed\n",
    "# source_to_target_edge_index = torch.tensor([[0,0],[0,1]])\n",
    "# transition_probability = torch.tensor([.3,.7])\n",
    "# vec_log_lh = lh_conv(x_source, source_to_target_edge_index, transition_probability)\n",
    "# print(vec_log_lh.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gettin zeroth order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 6], node_sequence=[7, 1], num_nodes=7, edge_weight=[6]),\n",
       " Data(edge_index=[2, 6], node_sequence=[7, 1], num_nodes=7, edge_weight=[6]),\n",
       " Data(edge_index=[2, 6], node_sequence=[7, 1], num_nodes=7, edge_weight=[6])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag_data.dags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "dag_graph = next(iter(DataLoader(dag_data.dags, batch_size=len(dag_data.dags)))).to(pp.config[\"torch\"][\"device\"])\n",
    "edge_index = dag_graph.edge_index\n",
    "node_sequence = dag_graph.node_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('0', '2', '3', '0'): 0,\n",
       " ('0', '2', '4', '1'): 1,\n",
       " ('1', '2', '4', '1'): 2,\n",
       " ('2', '3', '0', '2'): 3,\n",
       " ('2', '4', '1', '2'): 4,\n",
       " ('3', '0', '2', '3'): 5,\n",
       " ('3', '0', '2', '4'): 6,\n",
       " ('4', '1', '2', '4'): 7}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hon_4.mapping.id_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2381, 0.1905, 0.2857, 0.1429, 0.1429])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_nodes, counts = torch.unique(dag_graph.node_sequence, return_counts=True)\n",
    "\n",
    "node_emission_probabilities = counts/counts.sum()\n",
    "node_emission_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    988,   71248, 1101862])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# !!!!!!!!!!!!!!!!!!\n",
    "# Define the Cantor pairing function to work with tensors\n",
    "# https://en.wikipedia.org/wiki/Pairing_function\n",
    "def cantor_pairing(x, y):\n",
    "    return (x + y) * (x + y + 1) // 2 + y\n",
    "\n",
    "# Define the function to encode a list into a single integer\n",
    "def encode_tensor(lst):\n",
    "    if lst.size(1) == 0:\n",
    "        return torch.tensor(0)\n",
    "    else:\n",
    "        return cantor_pairing(lst[:, 0], encode_tensor(lst[:, 1:]))\n",
    "\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "\n",
    "# Apply the encode_list function row-wise\n",
    "result = encode_tensor(tensor)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we used this encoding also on node sequences, and then map supaths to ho-nodes ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {0: 0, 1: 1, 3: 2, 6: 3, 10: 4},\n",
       " 2: {9: 0, 13: 1, 42: 2, 88: 3, 6: 4, 16: 5},\n",
       " 3: {945: 0, 4004: 1, 4093: 2, 42: 3, 187: 4, 87: 5, 166: 6},\n",
       " 4: {945: 0,\n",
       "  17765: 1,\n",
       "  17953: 2,\n",
       "  4092: 3,\n",
       "  14362: 4,\n",
       "  450771: 5,\n",
       "  8034032: 6,\n",
       "  8398846: 7},\n",
       " 5: {8378370: 0,\n",
       "  103169428: 1,\n",
       "  101598824922: 2,\n",
       "  32272863207627: 3,\n",
       "  35270336461822: 4,\n",
       "  450771: 5,\n",
       "  157877561: 6,\n",
       "  161253856: 7},\n",
       " 6: {-3927727720672062055: 0,\n",
       "  -1544122977309695571: 1,\n",
       "  -3095025234462892546: 2,\n",
       "  101598824922: 3,\n",
       "  12462662686225827: 4,\n",
       "  13001403601822867: 5},\n",
       " 7: {-3927727720672062055: 0, 2441141984275317593: 1, 930405143996658085: 2}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cantor_to_honode_ixs_mapping = dict()\n",
    "for order, hon in m.layers.items():\n",
    "    # print(order)\n",
    "    # Creating cantor ixs for nodes in node sequence of hon\n",
    "    cantor_ids  = encode_tensor(hon.data.node_sequence)\n",
    "\n",
    "    # mapping cantor ids to node ids\n",
    "    cantor_to_node_ixs_mapping = dict(zip(\n",
    "        cantor_ids.tolist(),torch.arange(cantor_ids.shape[0]).tolist()\n",
    "        ))\n",
    "    # adding mapping for sink node\n",
    "    # cantor_to_node_ixs_mapping[sink_padding] = cantor_ids.shape[0]\n",
    "    dict_cantor_to_honode_ixs_mapping[order] = cantor_to_node_ixs_mapping\n",
    "dict_cantor_to_honode_ixs_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to apply the encoding before the padding.**\n",
    "The issue is that we don t know how the tensor encoding will work when applied to the 'sink_padding' (so, we need to apply the encoding before the padding!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import rnn as rnn_utils\n",
    "\n",
    "\n",
    "# # # https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
    "# def pad_collate(batch):\n",
    "#     # X =\n",
    "#     X_pad = rnn_utils.pad_sequence(batch, batch_first=True, padding_value = -1) # torch.as_tensor(target_train).view(-1, n_features).float()\n",
    "#     return X_pad\n",
    "\n",
    "\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, dag_data):\n",
    "#         self.list_node_seq_paths = [encode_tensor(dag.node_sequence.T) for dag in dag_data.dags]\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.list_node_seq_paths[index]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.list_node_seq_paths)\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset): # right now doesn t need to inherit from dataset (?)\n",
    "    def __init__(self, dag_data,\n",
    "                # dict_cantor_to_honode_ixs_mapping, \n",
    "                max_order):\n",
    "        self.max_order = max_order\n",
    "        self.walks_by_length = {}\n",
    "        self.walk_counts_by_length = {}\n",
    "        # self.dict_cantor_to_honode_ixs_mapping = dict_cantor_to_honode_ixs_mapping\n",
    "        for dag in dag_data.dags:\n",
    "            node_seq_path = dag.node_sequence.T[0]\n",
    "            l = len(node_seq_path)\n",
    "            if l not in self.walks_by_length:\n",
    "                self.walks_by_length[l] = []\n",
    "                self.walk_counts_by_length[l] = []\n",
    "            self.walks_by_length[l].append(node_seq_path)\n",
    "            self.walk_counts_by_length[l].append(int(dag.edge_weight.unique()))\n",
    "        self.total_sequences = sum(len(seq_list) for seq_list in self.walks_by_length.values())\n",
    "        self.walk_tensors_by_length = {l:torch.stack(walks, dim = 0) for l,walks in self.walks_by_length.items()}\n",
    "        self.cantor_encoded_walks_by_length = {l:self.cantor_encode(l) for l in self.walk_tensors_by_length}\n",
    "        self.bipartite_encoded_walks_by_length = {l:self.bipartite_encode(l) for l in self.walk_tensors_by_length}\n",
    "\n",
    "    def cantor_encode(self, walk_length):\n",
    "        list_cantor_node_ixs_tensors = []\n",
    "        for i in range(1,walk_length+1): # print(\"should probably start from zero\")\n",
    "            # need only one, not soirce target... \n",
    "            hon_ixs_tensor = self.walk_tensors_by_length[walk_length][:,max(0,i-self.max_order):i]\n",
    "            list_cantor_node_ixs_tensors.append(encode_tensor(hon_ixs_tensor))\n",
    "        return torch.stack(list_cantor_node_ixs_tensors, dim=1)\n",
    "\n",
    "\n",
    "    def bipartite_encode(self, walk_length):\n",
    "        list_cantor_node_ixs_tensors = []\n",
    "        for i in range(1,walk_length+1): # print(\"should probably start from zero\")\n",
    "            # need only one, not soirce target... \n",
    "            hon_ixs_tensor = self.walk_tensors_by_length[walk_length][:,max(0,i-self.max_order):i]\n",
    "            list_cantor_node_ixs_tensors.append(\n",
    "                encode_tensor(hon_ixs_tensor).apply_(\n",
    "                    dict_cantor_to_honode_ixs_mapping[min(i,self.max_order)].get))\n",
    "                \n",
    "                \n",
    "        return torch.stack(list_cantor_node_ixs_tensors, dim=1)\n",
    "\n",
    "    def __getitem__(self, l ,index):\n",
    "        return self.bipartite_encoded_walks_by_length[l][index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_sequences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cd_data = CustomDataset(dag_data,max_order=2)\n",
    "\n",
    "# data_loader = DataLoader(cd_data, batch_size=4, shuffle=False, collate_fn=pad_collate)\n",
    "\n",
    "\n",
    "# from torch.utils.data import DataLoader, Dataset, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still need:\n",
    "- account for number of observations of said path\n",
    "- deal with computing lh (passing those bip indices through message passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l =7\n",
    "source_to_target_from_walks = cd_data.bipartite_encoded_walks_by_length[l]\n",
    "path_counts = cd_data.walk_counts_by_length[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Lh_conv(torch_geometric.nn.MessagePassing):\n",
    "    def __init__(self):\n",
    "        super().__init__(aggr=\"sum\", flow=\"source_to_target\", node_dim = -1)\n",
    "    def forward(self, x_source, source_to_target_edge_index, transition_probability,N,M):\n",
    "        \n",
    "        # N = len(source_to_target_edge_index[0].unique())\n",
    "        # M = len(source_to_target_edge_index[1].unique())\n",
    "\n",
    "        return self.propagate(\n",
    "                    source_to_target_edge_index,\n",
    "                    size = (N,M),\n",
    "                    x = (x_source, None),\n",
    "                    transition_probability = transition_probability\n",
    "                    )\n",
    "\n",
    "    def message(self, x_j, transition_probability):\n",
    "        return x_j + np.log(transition_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th\n",
      "tensor([0.2381, 0.1905, 0.2857, 0.1429, 0.1429])\n",
      "tensor([-44.4876,     -inf,   0.0000,   0.0000,   0.0000])\n",
      "1\n",
      "source to target torch.Size([2, 3])\n",
      "transition probabilities torch.Size([7])\n",
      "ok\n",
      "torch.Size([6])\n",
      "2\n",
      "source to target torch.Size([2, 3])\n",
      "transition probabilities torch.Size([7])\n",
      "ok\n",
      "torch.Size([6])\n",
      "2\n",
      "source to target torch.Size([2, 3])\n",
      "transition probabilities torch.Size([7])\n",
      "ok\n",
      "torch.Size([6])\n",
      "2\n",
      "source to target torch.Size([2, 3])\n",
      "transition probabilities torch.Size([7])\n",
      "ok\n",
      "torch.Size([6])\n",
      "2\n",
      "source to target torch.Size([2, 3])\n",
      "transition probabilities torch.Size([7])\n",
      "ok\n",
      "torch.Size([6])\n",
      "2\n",
      "source to target torch.Size([2, 3])\n",
      "transition probabilities torch.Size([7])\n",
      "ok\n",
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_799/2390192856.py:18: RuntimeWarning: divide by zero encountered in log\n",
      "  return x_j + np.log(transition_probability)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_nodes = len(unique_nodes)\n",
    "lh_conv = Lh_conv()\n",
    "x_source = torch.zeros(1)# ((n_nodes,1)) \n",
    "# x_target = None # these are gonna be genetaed\n",
    "print(\"0-th\")\n",
    "print(node_emission_probabilities)\n",
    "M = n_nodes\n",
    "N = 1\n",
    "source_to_target_edge_index_zeroth = torch.stack([\n",
    "    torch.zeros_like(source_to_target_from_walks[:,0]),\n",
    "    source_to_target_from_walks[:,0]]\n",
    "    )\n",
    "vec_log_lh = lh_conv(\n",
    "    x_source,\n",
    "    source_to_target_edge_index_zeroth, \n",
    "    torch.pow(node_emission_probabilities[source_to_target_edge_index_zeroth[1]], torch.tensor(path_counts)),\n",
    "    N,\n",
    "    M\n",
    "    )\n",
    "print(vec_log_lh)\n",
    "# multiply for the number of time the path has been observed? \n",
    "\n",
    "# HERE is max_order\n",
    "# enough to just do it for all paths lenghts? \n",
    "# TODO: need to include path counts\n",
    "for i in range(0,l-1):\n",
    "    print(min(i+1,cd_data.max_order))\n",
    "    T = compute_transition_probabilities(m.layers[min(i+2,cd_data.max_order)])\n",
    "    M = m.layers[min(i+2,cd_data.max_order)].data.num_nodes\n",
    "    N = m.layers[min(i+1,cd_data.max_order)].data.num_nodes\n",
    "    source_to_target_edge_index = source_to_target_from_walks[:,i:i+2].T.squeeze() # TERRIBLE INDEXING HERE\n",
    "    print(\"source to target\",source_to_target_edge_index.shape)\n",
    "    print(\"transition probabilities\",T.shape)\n",
    "    vec_log_lh = lh_conv(\n",
    "        vec_log_lh, \n",
    "        source_to_target_edge_index, \n",
    "        torch.pow(T[source_to_target_edge_index[1]], torch.tensor(path_counts)),\n",
    "        N,\n",
    "        M\n",
    "        ) # weights given by target (e.g. given by edge weight n node to edge incdence) (CHECK!!!)\n",
    "    print(\"ok\")\n",
    "    print(vec_log_lh.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likely, there is no need need to go though a convolutional layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-739.3706)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate unique nodes and their counts\n",
    "unique_nodes, counts = torch.unique(dag_graph.node_sequence, return_counts=True)\n",
    "# Compute node emission probabilities\n",
    "node_emission_probabilities = counts / counts.sum()\n",
    "\n",
    "# Prepare source_to_target_edge_index_zeroth\n",
    "source_to_target_edge_index_zeroth = torch.stack([\n",
    "    torch.zeros_like(source_to_target_from_walks[:, 0]),\n",
    "    source_to_target_from_walks[:, 0]\n",
    "])\n",
    "\n",
    "# Compute log likelihood\n",
    "tot_log_lh = 0\n",
    "# Calculate log likelihood for the first step\n",
    "lh_l = torch.mul(torch.log(node_emission_probabilities[source_to_target_edge_index_zeroth[1]]), torch.tensor(path_counts))\n",
    "tot_log_lh += lh_l.sum()\n",
    "\n",
    "# Loop through the remaining steps\n",
    "for i in range(0, l - 1):\n",
    "    # Compute transition probabilities\n",
    "    T = compute_transition_probabilities(m.layers[min(i + 2, cd_data.max_order)])\n",
    "    # Prepare source_to_target_edge_index\n",
    "    source_to_target_edge_index = source_to_target_from_walks[:, i:i + 2].T.squeeze()\n",
    "    # Calculate log likelihood for current step\n",
    "    lh_l = torch.mul(torch.log(T[source_to_target_edge_index[1]]), torch.tensor(path_counts))\n",
    "    tot_log_lh += lh_l.sum()\n",
    "\n",
    "# Return total log likelihood\n",
    "tot_log_lh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**starting from temporal network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff for degrees of freedom etc.\n",
    "num_len_2_paths = hon_2.data.num_nodes\n",
    "num_nonzero_outdegrees = len(hon_2.data.edge_index[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tedges = [('0', '2', 1),('2', '3', 2), ('0', '2', 3), ('2', '3', 3), ('1', '2', 14), ('2', '4', 14), ('1', '2', 14),\n",
    "              ('2', '4', 15)]#, ('1', '2', 5), ('2', '4', 6)]\n",
    "t = pp.TemporalGraph.from_edge_list(tedges*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20., 20., 20., 20.])\n",
      "tensor([100., 200.])\n"
     ]
    }
   ],
   "source": [
    "hon_1 = m.layers[1]\n",
    "hon_2 = m.layers[2]\n",
    "print(hon_1.data.edge_weight)\n",
    "print(hon_2.data.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 20., 20., 20.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hon_1.data.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 20., 20., 20.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_ids = hon_1.data.edge_index[0]\n",
    "hon_1.data.edge_weight[source_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hon_1.data.edge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 40.,  0., 20.,  0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_outdegree = torch.zeros(hon_1.data.num_nodes)\n",
    "weighted_outdegree = weighted_outdegree.index_add_(\n",
    "    dim = 0, \n",
    "    index = hon_1.data.edge_index[0], \n",
    "    source = hon_1.data.edge_weight[source_ids]\n",
    "    )\n",
    "weighted_outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5000, 0.5000, 1.0000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_probabilities = hon_1.data.edge_weight[source_ids]/ weighted_outdegree[source_ids]\n",
    "transition_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this gives likelihood of all paths of lenght 2\n",
    "pp.MultiOrderModel.aggregate_edge_weight(\n",
    "    hon_2.data.edge_index,\n",
    "    transition_probabilities,\n",
    "    aggr=\"mul\"\n",
    "    )\n",
    "\n",
    "# the we need the number of times each path has occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "          3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " tensor([ 1.,  1.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  2.,\n",
       "          3.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  3.,  3.,  2.,  3., 14., 14.,\n",
       "         14., 14., 14., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 14.,\n",
       "         14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14.,\n",
       "         14., 14., 14., 14., 14., 14., 14., 14., 14., 14.]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_edge_index(t.data.edge_index, t.data.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_sequence = torch.arange(t.data.num_nodes, device=edge_index.device).unsqueeze(1)\n",
    "node_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n",
    "edge_weight = g.data.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for dimension 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m l1 \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiOrderModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_edge_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/pathpyG/src/pathpyG/core/MultiOrderModel.py:117\u001b[0m, in \u001b[0;36mMultiOrderModel.aggregate_edge_index\u001b[0;34m(edge_index, node_sequence, edge_weight)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_sequence\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     unique_nodes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(node_sequence\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mnode_sequence\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m     mapped_edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mnode_sequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     unique_nodes, inverse_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(node_sequence, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for dimension 0 with size 5"
     ]
    }
   ],
   "source": [
    "l1 = pp.MultiOrderModel.aggregate_edge_index(\n",
    "                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l1.data.edge_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cannot do the model selection on the temporal graph without the path extraction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
