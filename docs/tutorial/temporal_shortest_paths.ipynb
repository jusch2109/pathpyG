{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathpyG as pp\n",
    "from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Graph with 327 nodes, 11636 unique edges and 377016 events in [1385982080.0, 1386345600.0]\n",
      "\n",
      "Graph attributes\n",
      "\tsrc\t\t<class 'torch.Tensor'> -> torch.Size([377016])\n",
      "\tdst\t\t<class 'torch.Tensor'> -> torch.Size([377016])\n",
      "\tt\t\t<class 'torch.Tensor'> -> torch.Size([377016])\n",
      "\n",
      "1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected()\n",
    "print(t_sp)\n",
    "print(torch.unique(t_sp.data.t).size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Graph with 5 nodes, 5 unique edges and 5 events in [0.0, 2.0]\n",
      "\n",
      "Graph attributes\n",
      "\tsrc\t\t<class 'torch.Tensor'> -> torch.Size([5])\n",
      "\tdst\t\t<class 'torch.Tensor'> -> torch.Size([5])\n",
      "\tt\t\t<class 'torch.Tensor'> -> torch.Size([5])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2)])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 1, 3],\n",
      "        [1, 2, 2, 3, 4]])\n",
      "tensor([0., 0., 1., 1., 2.])\n",
      "tensor([0., 1., 2.])\n",
      "tensor([0, 0, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(t.data.edge_index)\n",
    "print(t.data.t)\n",
    "unique_t, reverse_idx = torch.unique(t.data.t, sorted=True, return_inverse=True)\n",
    "print(unique_t)\n",
    "print(reverse_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code with explosive memory usage due to computation of all second-order edges irrespective of time stamps\n",
    "def lift_order_not_efficient(g: pp.TemporalGraph, delta=1):\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n",
    "    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n",
    "\n",
    "    #print(edge_index)\n",
    "    #print(timestamps)\n",
    "\n",
    "    # TOOD: memory-efficient generation of temporal event DAG, where time-stamped edges are nodes\n",
    "    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=g.data.num_nodes)\n",
    "    # Map outdegree to each destination node to create an edge for each combination\n",
    "    # of incoming and outgoing edges for each destination node\n",
    "    outdegree_per_dst = outdegree[edge_index[1]]\n",
    "    num_new_edges = outdegree_per_dst.sum()\n",
    "    #print(num_new_edges)\n",
    "    # Create sources of new higher-order edges\n",
    "    # Issue here: we should only use the outdegree using time-respecting edges\n",
    "    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n",
    "    ho_edge_src_t = timestamps[ho_edge_srcs]\n",
    "    #print(ho_edge_srcs)\n",
    "    #print(ho_edge_src_t)\n",
    "\n",
    "    # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n",
    "    # of all previous nodes in the ordered sequence of nodes\n",
    "    ptrs = cumsum(outdegree, dim=0)[:-1]\n",
    "    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n",
    "    idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n",
    "    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n",
    "    ho_edge_dsts += idx_correction\n",
    "\n",
    "    ho_edge_dst_t = timestamps[ho_edge_dsts]\n",
    "    #print(ho_edge_dsts)\n",
    "    #print(ho_edge_dst_t)\n",
    "    filter = ho_edge_dst_t-ho_edge_src_t<=delta\n",
    "\n",
    "    ho_index = torch.stack([ho_edge_srcs[filter], ho_edge_dsts[filter]], dim=0)\n",
    "    #print(ho_index)\n",
    "    return ho_index.size(1), ho_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new memory-efficient code\n",
    "def lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):\n",
    "\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = g.data.edge_index, g.data.t\n",
    "\n",
    "    #print(edge_index)\n",
    "    #print(timestamps)\n",
    "\n",
    "    indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)\n",
    "\n",
    "    unique_t, reverse_idx = torch.unique(timestamps, sorted=True, return_inverse=True)\n",
    "    second_order = []\n",
    "    count = 0\n",
    "\n",
    "    # lift order: find possible continuations for edges in each time stamp\n",
    "    for i in tqdm(range(unique_t.size(0))):\n",
    "        t = unique_t[i]\n",
    "        #print('timestamp index ', i)\n",
    "        #print('timestamp ', t)\n",
    "        \n",
    "        # find indices of all source edges that occur at unique timestamp t\n",
    "        src_time_mask = (timestamps == t)\n",
    "        src_edges = edge_index[:,src_time_mask]\n",
    "        src_edge_idx = indices[src_time_mask]\n",
    "        #print(src_edges)\n",
    "        #print(src_edge_idx)\n",
    "\n",
    "        # find indices of all edges that can continue edges at tine t for given delta\n",
    "        dst_time_mask = (timestamps > t) & (timestamps <= t+delta)\n",
    "        dst_edges = edge_index[:,dst_time_mask]        \n",
    "        dst_edge_idx = indices[dst_time_mask]\n",
    "        #print(dst_edges)\n",
    "        #print(dst_edge_idx)\n",
    "\n",
    "        if dst_edge_idx.size(0)>0 and src_edge_idx.size(0)>0:\n",
    "\n",
    "            # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges        \n",
    "            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n",
    "            src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n",
    "            dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n",
    "            #print(src_edges)\n",
    "            #print(dst_edges)\n",
    "            ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n",
    "            second_order.append(ho_edge_index)\n",
    "            #print(ho_edge_index) \n",
    "            \n",
    "            # #print('dst', dst)\n",
    "            # src_mask = (edge_index[:,mask][0]==dst)\n",
    "            # ctd = edge_index[:,mask][:,src_mask]\n",
    "            # #print('continuations', ctd)\n",
    "            # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]        \n",
    "            # #print('ctd indx', ctd_indices)\n",
    "            # count += ctd_indices.size(0)\n",
    "    ho_index = torch.cat(second_order, dim=1)    \n",
    "    return ho_index.size(1), ho_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3077.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " tensor([[0, 0, 3],\n",
       "         [2, 3, 4]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_order_efficient(t, delta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " tensor([[0, 0, 3],\n",
       "         [2, 3, 4]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_order_not_efficient(t, delta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1157/1157 [00:08<00:00, 135.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3693050,\n",
       " tensor([[     0,      0,      0,  ..., 376991, 376991, 376991],\n",
       "         [   835,    885,    933,  ..., 376995, 377000, 377004]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_order_efficient(t_sp, delta=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lift_order_not_efficient(t_sp, delta=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 1],\n",
      "        [1, 3, 1, 3]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.cartesian_prod(torch.tensor([0,1]), torch.tensor([1,3])).t()\n",
    "# edge 0 = 0->1\n",
    "# edge 1 = 1->2\n",
    "# edge 2 = 0->1\n",
    "\n",
    "# combination 0,1:     0->1, 1->2\n",
    "# combination 0,2:     0->1, 0->1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [1, 1, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "src_edges = torch.index_select(t.data.edge_index, dim=1, index=x[0])\n",
    "print(src_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 1],\n",
      "        [2, 3, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "dst_edges = torch.index_select(t.data.edge_index, dim=1, index=x[1])\n",
    "print(dst_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [3]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #select all indices where \n",
    "torch.where(src_edges[1,:] == dst_edges[0,:])[0]\n",
    "x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1157/1157 [00:07<00:00, 148.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3693050,\n",
       " tensor([[     0,      0,      0,  ..., 376991, 376991, 376991],\n",
       "         [   835,    885,    933,  ..., 376995, 377000, 377004]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
