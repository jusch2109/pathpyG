{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pathpyG as pp\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "pp.config['torch']['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> 0\n",
      "b -> 1\n",
      "c -> 2\n",
      "d -> 3\n",
      "e -> 4\n",
      "f -> 5\n",
      "g -> 6\n",
      "h -> 7\n",
      "i -> 8\n",
      "\n",
      "9\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n",
    "              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n",
    "              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n",
    "              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n",
    "              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n",
    "t = pp.TemporalGraph.from_edge_list(tedges)\n",
    "print(t.mapping)\n",
    "print(t.N)\n",
    "print(t.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 17 nodes and 7 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/13\n",
      "Processing root 11/13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function pathpyG.algorithms.temporal.time_respecting_paths.<locals>.<lambda>()>,\n",
       "            {1: [['a', 'b'],\n",
       "              ['b', 'f'],\n",
       "              ['b', 'i'],\n",
       "              ['c', 'f'],\n",
       "              ['c', 'i'],\n",
       "              ['f', 'h'],\n",
       "              ['h', 'f'],\n",
       "              ['h', 'i'],\n",
       "              ['i', 'b']],\n",
       "             3: [['a', 'b', 'c', 'd'],\n",
       "              ['a', 'b', 'c', 'e'],\n",
       "              ['c', 'f', 'a', 'g']],\n",
       "             2: [['a', 'c', 'h'], ['a', 'g', 'h']]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.time_respecting_paths(t, delta=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 17 nodes and 7 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/13\n",
      "Processing root 11/13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function pathpyG.algorithms.centrality.temporal_closeness_centrality.<locals>.<lambda>()>,\n",
       "            {'b': 2.0,\n",
       "             'd': 0.3333333333333333,\n",
       "             'e': 0.3333333333333333,\n",
       "             'f': 3.0,\n",
       "             'g': 0.3333333333333333,\n",
       "             'h': 1.5,\n",
       "             'i': 3.0,\n",
       "             'a': 0.0,\n",
       "             'c': 0.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.centrality.temporal_closeness_centrality(t, delta=5, normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 17 nodes and 7 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/13\n",
      "Processing root 11/13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function pathpyG.algorithms.centrality.temporal_betweenness_centrality.<locals>.<lambda>()>,\n",
       "            {'b': 2.0,\n",
       "             'c': 2.5,\n",
       "             'g': 0.5,\n",
       "             'f': 1.0,\n",
       "             'a': 1.0,\n",
       "             'd': 0,\n",
       "             'e': 0,\n",
       "             'h': 0,\n",
       "             'i': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.centrality.temporal_betweenness_centrality(t, delta=5, normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 17 nodes and 7 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/13\n",
      "Processing root 11/13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>()>,\n",
       "             {'a': defaultdict(set,\n",
       "                          {'b': {('a', 'b')},\n",
       "                           'd': {('a', 'b', 'c', 'd')},\n",
       "                           'e': {('a', 'b', 'c', 'e')},\n",
       "                           'h': {('a', 'c', 'h'), ('a', 'g', 'h')}}),\n",
       "              'b': defaultdict(set, {'f': {('b', 'f')}, 'i': {('b', 'i')}}),\n",
       "              'c': defaultdict(set,\n",
       "                          {'f': {('c', 'f')},\n",
       "                           'i': {('c', 'i')},\n",
       "                           'g': {('c', 'f', 'a', 'g')}}),\n",
       "              'f': defaultdict(set, {'h': {('f', 'h')}}),\n",
       "              'h': defaultdict(set, {'f': {('h', 'f')}, 'i': {('h', 'i')}}),\n",
       "              'i': defaultdict(set, {'b': {('i', 'b')}})}),\n",
       " defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>()>,\n",
       "             {'a': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'b': 1, 'd': 3, 'e': 3, 'h': 2}),\n",
       "              'b': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'f': 1, 'i': 1}),\n",
       "              'c': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'f': 1, 'i': 1, 'g': 3}),\n",
       "              'f': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'h': 1}),\n",
       "              'h': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'f': 1, 'i': 1}),\n",
       "              'i': defaultdict(<function pathpyG.algorithms.temporal.temporal_shortest_paths.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {'b': 1})}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.temporal_shortest_paths(t, delta=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> 0\n",
      "b -> 1\n",
      "c -> 2\n",
      "d -> 3\n",
      "\n",
      "4\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n",
    "              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\n",
    "t = pp.TemporalGraph.from_edge_list(tedges)\n",
    "print(t.mapping)\n",
    "print(t.N)\n",
    "print(t.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 10 nodes and 14 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function pathpyG.algorithms.temporal.time_respecting_paths.<locals>.<lambda>()>,\n",
       "            {2: [['a', 'b', 'a'],\n",
       "              ['a', 'b', 'a'],\n",
       "              ['d', 'c', 'b'],\n",
       "              ['d', 'c', 'd']],\n",
       "             4: [['a', 'b', 'c', 'b', 'a'],\n",
       "              ['a', 'b', 'a', 'b', 'a'],\n",
       "              ['a', 'b', 'c', 'b', 'a'],\n",
       "              ['a', 'b', 'a', 'b', 'a']],\n",
       "             3: [['a', 'b', 'c', 'b'],\n",
       "              ['a', 'b', 'c', 'd'],\n",
       "              ['a', 'b', 'c', 'b'],\n",
       "              ['a', 'b', 'c', 'd']]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = pp.algorithms.time_respecting_paths(t, delta=5)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(paths[x]) for x in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 17 nodes and 3 edges\n",
      "\n",
      "Node attributes\n",
      "\tnode_sequence\t\t<class 'torch.Tensor'> -> torch.Size([17, 2])\n",
      "\n",
      "Edge attributes\n",
      "\tedge_weight\t\t<class 'torch.Tensor'> -> torch.Size([3])\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "(('a', 'c'), ('c', 'h')) tensor(1.)\n",
      "(('a', 'g'), ('g', 'h')) tensor(1.)\n",
      "(('c', 'f'), ('f', 'a')) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "m = pp.MultiOrderModel.from_temporal_graph(t, max_order=4, delta=2)\n",
    "print(m.layers[2])\n",
    "for i, e in enumerate(m.layers[2].edges):\n",
    "    print(e, m.layers[2].data.edge_weight[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1 -> slow\n",
    "def temporal_shortest_paths(g: pp.TemporalGraph, delta, max_k) -> defaultdict:\n",
    "    \"\"\"\n",
    "    Calculates all shortest paths between all pairs of nodes \n",
    "    based on a set of empirically observed paths.\n",
    "    \"\"\"\n",
    "    sp = defaultdict(lambda: defaultdict(set))\n",
    "    sp_lengths = torch.full((g.N, g.N), float('inf'))\n",
    "    sp_lengths.fill_diagonal_(float(0))\n",
    "    out_degree=degree(g.data.edge_index[0],num_nodes=g.N)\n",
    "    in_degree =degree(g.data.edge_index[1],num_nodes=g.N)\n",
    "\n",
    "    sp_lengths[out_degree==0]=0\n",
    "    sp_lengths[:,in_degree==0]=0\n",
    "    print(sp_lengths)\n",
    "\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n",
    "    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n",
    "    k = 1\n",
    "    while torch.max(sp_lengths) > k and edge_index.size(1)>0 and k < max_k:\n",
    "\n",
    "        print(f'k = {k}, edge_index size = {edge_index.size(1)}')\n",
    "        #print(f'node_sequences = {node_sequences}')\n",
    "        # check for shorter paths with length k\n",
    "        src, tgt = edge_index\n",
    "        for i in range(edge_index.size(1)):\n",
    "            u = node_sequence[src[i]][0]\n",
    "            v = node_sequence[tgt[i]][-1]\n",
    "            if k < sp_lengths[u][v]:\n",
    "                path = torch.cat([node_sequence[src[i]], v.unsqueeze(dim=0)])\n",
    "                sp_lengths[u][v] = k\n",
    "                sp[u][v] = set([g.mapping.to_id(x.item()) for x in path])\n",
    "            elif k == sp_lengths[u][v]:\n",
    "                path = torch.cat([node_sequence[src[i]], v.unsqueeze(dim=0)])\n",
    "                sp[u][v].add(tuple([g.mapping.to_id(x.item()) for x in path]))\n",
    "                 \n",
    "\n",
    "        if k==1:\n",
    "            null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n",
    "            # Update node sequences\n",
    "            node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n",
    "            # Remove non-time-respecting higher-order edges\n",
    "            time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n",
    "            non_negative_mask = time_diff > 0\n",
    "            delta_mask = time_diff <= delta\n",
    "            time_respecting_mask = non_negative_mask & delta_mask\n",
    "            edge_index = null_model_edge_index[:, time_respecting_mask]\n",
    "        else:\n",
    "            edge_index, node_sequence, _, _ = pp.MultiOrderModel.iterate_lift_order(edge_index, node_sequence, mapping=g.mapping)\n",
    "        k += 1\n",
    "    return sp_lengths, sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "def routes_from_node(g, v, node_sequence, mapping):\n",
    "    \"\"\"\n",
    "    Constructs all paths from node v to any leaf node\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v:\n",
    "        node from which to start\n",
    "    node_mapping: dict\n",
    "        an optional mapping from node to a different set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Counter\n",
    "    \"\"\"\n",
    "    # Collect temporary paths, indexed by the target node\n",
    "    temp_paths = defaultdict(list)\n",
    "    temp_paths[v] = [[mapping.to_id(node_sequence[v][0].item())]]\n",
    "\n",
    "    # set of unprocessed nodes\n",
    "    queue = {v}\n",
    "\n",
    "    while queue:\n",
    "        # take one unprocessed node\n",
    "        x = queue.pop()\n",
    "\n",
    "        # successors of x expand all temporary\n",
    "        # paths, currently ending in x\n",
    "        s = g.get_successors(x)\n",
    "        for w in s:\n",
    "            w = w.item()\n",
    "            for p in temp_paths[x]:\n",
    "                temp_paths[w].append(p + [mapping.to_id(node_sequence[w][1].item())])\n",
    "            queue.add(w)\n",
    "        if s.size(0) > 0:\n",
    "            del temp_paths[x]\n",
    "    # flatten dictionary\n",
    "    return temp_paths    \n",
    "\n",
    "def temporal_shortest_paths(g: pp.TemporalGraph, delta) -> defaultdict:\n",
    "    \"\"\"\n",
    "    Calculates all shortest paths between all pairs of nodes \n",
    "    based on a set of empirically observed paths.\n",
    "    \"\"\"\n",
    "    sp = defaultdict(lambda: defaultdict(set))\n",
    "    sp_lengths = torch.full((g.N, g.N), float('inf'))\n",
    "    sp_lengths.fill_diagonal_(float(0))\n",
    "    out_degree=degree(g.data.edge_index[0],num_nodes=g.N)\n",
    "    in_degree =degree(g.data.edge_index[1],num_nodes=g.N)\n",
    "\n",
    "    sp_lengths[out_degree==0]=0\n",
    "    sp_lengths[:,in_degree==0]=0\n",
    "    print(sp_lengths)\n",
    "\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n",
    "    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n",
    "    k = 1\n",
    "\n",
    "    # second-order edge index\n",
    "    null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n",
    "    # Update node sequences\n",
    "    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n",
    "    # Remove non-time-respecting higher-order edges\n",
    "    time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n",
    "    non_negative_mask = time_diff > 0\n",
    "    delta_mask = time_diff <= delta\n",
    "    time_respecting_mask = non_negative_mask & delta_mask\n",
    "    edge_index = null_model_edge_index[:, time_respecting_mask]\n",
    "    \n",
    "    # identify root nodes with in-degree zero\n",
    "    in_degree = degree(edge_index[1],num_nodes=g.M)\n",
    "    roots = torch.where(in_degree==0)[0]\n",
    "\n",
    "    # create traversable graph\n",
    "    event_dag = pp.Graph.from_edge_index(edge_index)\n",
    "    print(event_dag)\n",
    "\n",
    "    # count all longest time-respecting paths in the temporal graph\n",
    "    paths = []\n",
    "    i = 0\n",
    "    for r in roots:\n",
    "        print(f'processing root {i+1}/{roots.size(0)}')\n",
    "        root_paths = routes_from_node(event_dag, r.item(), node_sequence, g.mapping)\n",
    "        print(f'\\t found {len(root_paths)} paths')\n",
    "        for x in root_paths:\n",
    "            for p in root_paths[x]:\n",
    "                paths.append(p)\n",
    "        i += 1\n",
    "    print(len(paths))\n",
    "    return sp_lengths, sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_lengths, sp = temporal_shortest_paths(t, delta=100)\n",
    "print(sp_lengths)\n",
    "print(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Graph with 89 nodes, 947 unique edges and 1911 events in [0.0, 1438.0]\n",
      "\n",
      "Graph attributes\n",
      "\tt\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\tsrc\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\tdst\t\t<class 'torch.Tensor'> -> torch.Size([1911])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t = pp.TemporalGraph.from_csv('ants_1_1.tedges')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = temporal_shortest_paths(t, delta=30)\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 1910 nodes and 2518 edges\n",
      "\n",
      "Graph attributes\n",
      "\tnum_nodes\t\t<class 'int'>\n",
      "\n",
      "Processing root 1/597\n",
      "Processing root 11/597\n",
      "Processing root 21/597\n",
      "Processing root 31/597\n",
      "Processing root 41/597\n",
      "Processing root 51/597\n",
      "Processing root 61/597\n",
      "Processing root 71/597\n",
      "Processing root 81/597\n",
      "Processing root 91/597\n",
      "Processing root 101/597\n",
      "Processing root 111/597\n",
      "Processing root 121/597\n",
      "Processing root 131/597\n",
      "Processing root 141/597\n",
      "Processing root 151/597\n",
      "Processing root 161/597\n",
      "Processing root 171/597\n",
      "Processing root 181/597\n",
      "Processing root 191/597\n",
      "Processing root 201/597\n",
      "Processing root 211/597\n",
      "Processing root 221/597\n",
      "Processing root 231/597\n",
      "Processing root 241/597\n",
      "Processing root 251/597\n",
      "Processing root 261/597\n",
      "Processing root 271/597\n",
      "Processing root 281/597\n",
      "Processing root 291/597\n",
      "Processing root 301/597\n",
      "Processing root 311/597\n",
      "Processing root 321/597\n",
      "Processing root 331/597\n",
      "Processing root 341/597\n",
      "Processing root 351/597\n",
      "Processing root 361/597\n",
      "Processing root 371/597\n",
      "Processing root 381/597\n",
      "Processing root 391/597\n",
      "Processing root 401/597\n",
      "Processing root 411/597\n",
      "Processing root 421/597\n",
      "Processing root 431/597\n",
      "Processing root 441/597\n",
      "Processing root 451/597\n",
      "Processing root 461/597\n",
      "Processing root 471/597\n",
      "Processing root 481/597\n",
      "Processing root 491/597\n",
      "Processing root 501/597\n",
      "Processing root 511/597\n",
      "Processing root 521/597\n",
      "Processing root 531/597\n",
      "Processing root 541/597\n",
      "Processing root 551/597\n",
      "Processing root 561/597\n",
      "Processing root 571/597\n",
      "Processing root 581/597\n",
      "Processing root 591/597\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "paths = pp.algorithms.time_respecting_paths(t, delta=30)\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sp_lengths[sp_lengths < 100].flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0,1,2])\n",
    "b = torch.tensor([1,2,3])\n",
    "torch.cat([a, b[-1].unsqueeze(dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in torch.tensor([0,1]):\n",
    "    print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
